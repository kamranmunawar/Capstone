{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d804631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import os\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch  import fit_gpytorch_model\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f79313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea0f5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_inputs = np.load(\"initial_inputs1.npy\")\n",
    "f1_outputs = np.load(\"initial_outputs1.npy\")\n",
    "f1_inputs_2 = np.load(\"initial_inputs2.npy\")\n",
    "f1_outputs_2 = np.load(\"initial_outputs2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6198b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_inputs = np.concatenate((f1_inputs, f1_inputs_2)) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.201607 , 0.5658698]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.785688, 0.49287]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.701023, 0.702999]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.767155, 0.801202]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.756262, 0.621414]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.721023, 0.682999]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.707689, 0.722999]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.716578, 0.705221]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.703245, 0.682999]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.609401, 0.605101]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.629401, 0.589545]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.629401, 0.616212]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.649401, 0.622878]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.631623, 0.636212]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.611623, 0.656212]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.642734, 0.616212]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.651623, 0.620656]]))) \n",
    "f1_inputs = np.concatenate((f1_inputs, np.array([[0.642734, 0.616212]]))) \n",
    "\n",
    "f1_outputs = np.concatenate((f1_outputs,f1_outputs_2)) \n",
    "f1_outputs = np.append(f1_outputs,-5.9027047474104416e-49)\n",
    "f1_outputs = np.append(f1_outputs,1.4694233057027134e-30)\n",
    "f1_outputs = np.append(f1_outputs,6.013687404741693e-08)\n",
    "f1_outputs = np.append(f1_outputs,1.029025518149088e-34)\n",
    "f1_outputs = np.append(f1_outputs,3.1568882670317357e-12)\n",
    "f1_outputs = np.append(f1_outputs,9.594441158769377e-09)\n",
    "f1_outputs = np.append(f1_outputs,4.4984959147048566e-11)\n",
    "f1_outputs = np.append(f1_outputs,6.25317474883913e-10)\n",
    "f1_outputs = np.append(f1_outputs,1.2990004780975896e-06)\n",
    "f1_outputs = np.append(f1_outputs,0.1971687803797823)\n",
    "f1_outputs = np.append(f1_outputs,0.0019282695144167755)\n",
    "f1_outputs = np.append(f1_outputs,1.378994567184674)\n",
    "f1_outputs = np.append(f1_outputs,0.6197596252221214)\n",
    "f1_outputs = np.append(f1_outputs,1.6960217184989461)\n",
    "f1_outputs = np.append(f1_outputs,0.12963516015284113)\n",
    "f1_outputs = np.append(f1_outputs,0.8437573006254239)\n",
    "f1_outputs = np.append(f1_outputs,0.4426566990166618)\n",
    "f1_outputs = np.append(f1_outputs,0.8437573006254239)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d2d3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_value = np.linspace(0.01, 0.09, 10)\n",
    "n_dims = 2 \n",
    "beta =0.01# 1.6262626262626263\n",
    "np.random.seed(42)\n",
    "train_X = torch.tensor(f1_inputs)\n",
    "train_Y = torch.tensor(f1_outputs).reshape(len(f1_outputs),-1)\n",
    "best_y = np.max(train_Y.numpy())\n",
    "best_x = train_X[np.argmax(train_Y.numpy())]\n",
    "noise_level =0.01 # 4\n",
    "candidate_list = []\n",
    "best_x_list = []\n",
    "\n",
    "#train_X = train_X1[0].reshape(8,-1)\n",
    "#train_Y = train_Y1[0].reshape(1,-1)\n",
    "\n",
    "for i in range(len(variable_value)):\n",
    "    #noise_level = variable_value[i]\n",
    "   \n",
    "\n",
    "    def function_1(x1,x2, noise_level=noise_level):\n",
    "        result = np.sin(5 * x1+4*x2) * (1 - np.tanh(x1 ** 2) - np.tanh(x2))\\\n",
    "        + np.random.randn() * noise_level\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    gp = SingleTaskGP(train_X, train_Y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    UCB = UpperConfidenceBound(gp, beta=beta)\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(n_dims), torch.ones(n_dims)])\n",
    "    candidate, _  = optimize_acqf(\n",
    "        UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=200,\n",
    "    )\n",
    "\n",
    "\n",
    "    x1,x2 = candidate.numpy().ravel().tolist()\n",
    "    # Get the next value for the function from the script\n",
    "\n",
    "    y_next = function_1(x1,x2)\n",
    "\n",
    "    if y_next > best_y:\n",
    "        best_y = y_next\n",
    "        best_x = x1,x2\n",
    "\n",
    "\n",
    "    y_next = torch.tensor(y_next).unsqueeze(-1)\n",
    "\n",
    "    train_X = torch.cat([train_X,candidate])\n",
    "    train_Y = torch.cat([train_Y,y_next.unsqueeze(-1)])\n",
    "    candidate_list.append(candidate) \n",
    "    best_x_list.append(best_x)\n",
    "    #print(f\"Next point: {candidate} \\n Next Y {y_next}  Best_y, {best_y}\")\n",
    "    #print(f\"beta :{beta} noise_level :{noise_level}\")\n",
    "    #print(f\"Next point: {candidate} \\n Next Y {y_next}\")\n",
    "    #print(f\"best_x:{best_x}Best_y,{best_y}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a847df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64),\n",
       " tensor([0.6316, 0.6362], dtype=torch.float64)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_x_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
