{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa90f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import os\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch  import fit_gpytorch_model\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1ffaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4_inputs = np.load(\"initial_inputs.npy\")\n",
    "f4_outputs = np.load(\"initial_outputs.npy\")\n",
    "f4_inputs_2 = np.load(\"initial_inputs2.npy\")\n",
    "f4_outputs_2 = np.load(\"initial_outputs2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1635115",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4_inputs = np.concatenate((f4_inputs, f4_inputs_2)) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.533179, 0.320368, 0.682501, 0.312599]])))\n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.444629, 0.320368, 0.808875, 0.908167]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.607765, 0.358771, 0.405825, 0.251007]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.687501, 0.84587 , 0.833788, 0.143186]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.557765, 0.448771, 0.445825, 0.269007]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.507765, 0.498771, 0.395825, 0.319007]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.457765, 0.548771, 0.345825, 0.369007]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.407765, 0.498771, 0.295825, 0.419007]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.357765, 0.448771, 0.245825, 0.469007]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.325901, 0.423101, 0.406001, 0.415501]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.287012, 0.439767, 0.456001, 0.432167]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.38256 , 0.363705, 0.389898, 0.390221]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.331802, 0.389754, 0.375876, 0.369452]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.331882, 0.379388, 0.371487, 0.422793]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.301994, 0.331229, 0.44261 , 0.408753]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.402732, 0.392983, 0.412051, 0.411811]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.394307, 0.324568, 0.266869, 0.332541]]))) \n",
    "f4_inputs = np.concatenate((f4_inputs, np.array([[0.395203, 0.398125, 0.414027, 0.449168]]))) \n",
    "\n",
    "f4_outputs = np.concatenate((f4_outputs,f4_outputs_2))\n",
    "f4_outputs = np.append(f4_outputs,-7.457831737943366)\n",
    "f4_outputs = np.append(f4_outputs,-20.190789652235313)\n",
    "f4_outputs = np.append(f4_outputs,-4.588426873216477)\n",
    "f4_outputs = np.append(f4_outputs,-24.332647737297297)\n",
    "f4_outputs = np.append(f4_outputs,-3.685845588546609)\n",
    "f4_outputs = np.append(f4_outputs,-2.8122115680390354)\n",
    "f4_outputs = np.append(f4_outputs,-2.590293835023562)\n",
    "f4_outputs = np.append(f4_outputs,-2.0998084663837484)\n",
    "f4_outputs = np.append(f4_outputs,-2.368538951646705)\n",
    "f4_outputs = np.append(f4_outputs,0.13490612991991258)\n",
    "f4_outputs = np.append(f4_outputs,-1.3532237087009196)\n",
    "f4_outputs = np.append(f4_outputs,0.15448865125965527)\n",
    "f4_outputs = np.append(f4_outputs,-0.02620181983396419)\n",
    "f4_outputs = np.append(f4_outputs,0.19106899681514777)\n",
    "f4_outputs = np.append(f4_outputs,-1.0065878357155316)\n",
    "f4_outputs = np.append(f4_outputs,0.48394520320252754)\n",
    "f4_outputs = np.append(f4_outputs,-1.70575402025506)\n",
    "f4_outputs = np.append(f4_outputs,-0.1020328389196119)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1ce70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_value = np.linspace(1, 10, 10)\n",
    "n_dims = 4\n",
    "beta =0.001# 1.1818181818181819\n",
    "np.random.seed(42)\n",
    "train_X = torch.tensor(f4_inputs)\n",
    "train_Y = torch.tensor(f4_outputs).reshape(len(f4_outputs),-1)\n",
    "best_y = np.max(train_Y.numpy())\n",
    "best_x = train_X[np.argmax(train_Y.numpy())]\n",
    "noise_level =0.001 #6.909090909090909\n",
    "candidate_list = []\n",
    "best_x_list = []\n",
    "\n",
    "for i in range(len(variable_value)):\n",
    "    #noise_level = variable_value[i]\n",
    "   \n",
    "    def function_8(x1,x2,x3,x4, noise_level=noise_level):\n",
    "        return np.sin(5 * x1+4*x2) * (1 - np.tanh(x1 ** 2) - np.tanh(x2)) + \\\n",
    "            np.sin(1 * x3+4*x4) * (1 - np.tanh(x3 ** 2) - np.tanh(x4)) + \\\n",
    "                   + np.random.randn() * noise_level\n",
    "    \n",
    "    \n",
    "    gp = SingleTaskGP(train_X, train_Y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    #EI = qExpectedImprovement(model=gp , best_f=best_y)\n",
    "\n",
    "    UCB = UpperConfidenceBound(gp, beta=beta)\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(n_dims), torch.ones(n_dims)])\n",
    "    candidate, _  = optimize_acqf(\n",
    "        UCB, bounds=bounds, q=1, num_restarts=50, raw_samples=200,\n",
    "    )\n",
    "\n",
    "\n",
    "    x1,x2,x3,x4 = candidate.numpy().ravel().tolist()\n",
    "    # Get the next value for the function from the script\n",
    "\n",
    "    y_next = function_8(x1,x2,x3,x4)\n",
    "\n",
    "    if y_next > best_y:\n",
    "        best_y = y_next\n",
    "        best_x = x1,x2,x3,x4\n",
    "\n",
    "\n",
    "    y_next = torch.tensor(y_next).unsqueeze(-1)\n",
    "\n",
    "    train_X = torch.cat([train_X,candidate])\n",
    "    train_Y = torch.cat([train_Y,y_next.unsqueeze(-1)])\n",
    "    candidate_list.append(candidate) \n",
    "    best_x_list.append(best_x)\n",
    "    #print(f\"Next point: {candidate} \\n Next Y {y_next}  Best_y, {best_y}\")\n",
    "    #print(f\"beta :{beta} noise_level :{noise_level}\")\n",
    "    #print(f\"Next point: {candidate} \\n Next Y {y_next}\")\n",
    "    #print(f\"best_x:{best_x}Best_y,{best_y}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f73067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3858, 0.3840, 0.3988, 0.4009]]),\n",
       " tensor([[0.3854, 0.3850, 0.3964, 0.4005]]),\n",
       " tensor([[0.3864, 0.3842, 0.3974, 0.4005]]),\n",
       " tensor([[0.3846, 0.3858, 0.3953, 0.4005]]),\n",
       " tensor([[0.3845, 0.3871, 0.3938, 0.4004]]),\n",
       " tensor([[0.3835, 0.3866, 0.3942, 0.4007]]),\n",
       " tensor([[0.3829, 0.3871, 0.3937, 0.4008]]),\n",
       " tensor([[0.3823, 0.3875, 0.3932, 0.4010]]),\n",
       " tensor([[0.3816, 0.3879, 0.3928, 0.4012]]),\n",
       " tensor([[0.3809, 0.3883, 0.3924, 0.4014]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be03ebcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64),\n",
       " tensor([0.4027, 0.3930, 0.4121, 0.4118], dtype=torch.float64)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d1755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
