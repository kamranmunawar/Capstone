{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b772fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch  import fit_gpytorch_model\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import RBF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc8cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "f7_inputs = np.load(\"initial_inputs.npy\")\n",
    "f7_outputs = np.load(\"initial_outputs.npy\")\n",
    "f7_inputs_2 = np.load(\"initial_inputs2.npy\")\n",
    "f7_outputs_2 = np.load(\"initial_outputs2.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ded5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f7_inputs = np.concatenate((f7_inputs, f7_inputs_2)) \n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.63626 , 0.749201, 0.1892  , 0.68919 , 0.593918, 0.199029]]))) \n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.368718, 0.581611, 0.450298, 0.514296, 0.368287, 0.298886]]))) \n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.060895, 0.501672, 0.251022, 0.221018, 0.450428, 0.750969]]))) \n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.531569, 0.712456, 0.129994, 0.411075, 0.641262, 0.863832]]))) \n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.055673, 0.489451, 0.245211, 0.215896, 0.413761, 0.440428]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.574342, 0.678895, 0.533896, 0.92418 , 0.554493, 0.523589]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.100001, 0.495555, 0.297777, 0.198888, 0.396666, 0.693333]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.088889, 0.493332, 0.282221, 0.205554, 0.403332, 0.695555]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.097778, 0.497777, 0.299999, 0.192221, 0.385554, 0.713333]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.699728, 0.60899 , 0.530807, 0.004961, 0.23617 , 0.606289]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.189374, 0.254933, 0.38873 , 0.226883, 0.365509, 0.859723]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.193819, 0.254933, 0.393174, 0.231327, 0.361065, 0.859723]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.039062, 0.040611, 0.422165, 0.057258, 0.711931, 0.146917]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.200485, 0.266044, 0.39984 , 0.237993, 0.354398, 0.848611]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.211596, 0.286044, 0.410951, 0.249104, 0.343286, 0.828611]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.222707, 0.306044, 0.422062, 0.260215, 0.332174, 0.808611]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.229373, 0.321599, 0.428728, 0.266881, 0.325507, 0.793055]])))\n",
    "f7_inputs = np.concatenate((f7_inputs, np.array([[0.222706, 0.337154, 0.422061, 0.264658, 0.327729, 0.777499]])))\n",
    "\n",
    "f7_outputs = np.concatenate((f7_outputs,f7_outputs_2)) \n",
    "f7_outputs = np.append(f7_outputs,0.6531409333073234)\n",
    "f7_outputs = np.append(f7_outputs,0.8720881396978204)\n",
    "f7_outputs = np.append(f7_outputs,1.159982626521815)\n",
    "f7_outputs = np.append(f7_outputs,0.06394964228046124)\n",
    "f7_outputs = np.append(f7_outputs,0.9892232332511364)\n",
    "f7_outputs = np.append(f7_outputs,0.02270238658904679)\n",
    "f7_outputs = np.append(f7_outputs,1.5980696671819323)\n",
    "f7_outputs = np.append(f7_outputs,1.552462506402468)\n",
    "f7_outputs = np.append(f7_outputs,1.5958875261823084)\n",
    "f7_outputs = np.append(f7_outputs,0.31095147109238114)\n",
    "f7_outputs = np.append(f7_outputs,2.1108344344203425)\n",
    "f7_outputs = np.append(f7_outputs,2.141437825123243)\n",
    "f7_outputs = np.append(f7_outputs,0.14128327861643816)\n",
    "f7_outputs = np.append(f7_outputs,2.2404023030732505)\n",
    "f7_outputs = np.append(f7_outputs,2.3917589697962973)\n",
    "f7_outputs = np.append(f7_outputs,2.5103520273309883)\n",
    "f7_outputs = np.append(f7_outputs,2.57198926677023)\n",
    "f7_outputs = np.append(f7_outputs,2.5936857026275053)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9639158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_value = np.linspace(1, 10, 10)\n",
    "n_dims = 6\n",
    "beta =0.001# 1.1818181818181819\n",
    "np.random.seed(42)\n",
    "train_X = torch.tensor(f7_inputs)\n",
    "train_Y = torch.tensor(f7_outputs).reshape(len(f7_outputs),-1)\n",
    "best_y = np.max(train_Y.numpy())\n",
    "best_x = train_X[np.argmax(train_Y.numpy())]\n",
    "noise_level =0.001#1.2727272727272727\n",
    "candidate_list = []\n",
    "best_x_list = []\n",
    "\n",
    "for i in range(len(variable_value)):\n",
    "    #beta = variable_value[i]\n",
    "   \n",
    "    def function_7(x1,x2,x3,x4,x5,x6, noise_level=noise_level):\n",
    "            return np.sin(5 * x1+4*x2) * (1 - np.tanh(x1 ** 2) - np.tanh(x2)) + \\\n",
    "            np.sin(1 * x3+4*x4) * (1 - np.tanh(x3 ** 2) - np.tanh(x4)) + \\\n",
    "            np.sin(1 * x5+4*x6) * (1 - np.tanh(x5 ** 2) - np.tanh(x6)) + \\\n",
    "              + \\\n",
    "                   + np.random.randn() * noise_level\n",
    "\n",
    "    \n",
    "    gp = SingleTaskGP(train_X, train_Y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    #EI = qExpectedImprovement(model=gp , best_f=best_y)\n",
    "\n",
    "    UCB = UpperConfidenceBound(gp, beta=beta)\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(n_dims), torch.ones(n_dims)])\n",
    "    candidate, _  = optimize_acqf(\n",
    "        UCB, bounds=bounds, q=1, num_restarts=200, raw_samples=200,\n",
    "    )\n",
    "\n",
    "\n",
    "    x1,x2,x3,x4,x5,x6 = candidate.numpy().ravel().tolist()\n",
    "    # Get the next value for the function from the script\n",
    "\n",
    "    y_next = function_7(x1,x2,x3,x4,x5,x6)\n",
    "\n",
    "    if y_next > best_y:\n",
    "        best_y = y_next\n",
    "        best_x = x1,x2,x3,x4,x5,x6\n",
    "\n",
    "\n",
    "    y_next = torch.tensor(y_next).unsqueeze(-1)\n",
    "\n",
    "    train_X = torch.cat([train_X,candidate])\n",
    "    train_Y = torch.cat([train_Y,y_next.unsqueeze(-1)])\n",
    "    candidate_list.append(candidate) \n",
    "    best_x_list.append(best_x)\n",
    "    #print(f\"Next point: {candidate} \\n Next Y {y_next}  Best_y, {best_y}\")\n",
    "    #print(f\"beta :{beta} noise_level :{noise_level}\")\n",
    "    #print(f\"Next point: {candidate} \\n Next Y {y_next}\")\n",
    "    #print(f\"best_x:{best_x}Best_y,{best_y}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f356ca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64),\n",
       " tensor([0.2227, 0.3372, 0.4221, 0.2647, 0.3277, 0.7775], dtype=torch.float64)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta :1.1818181818181819 noise_level :1.2727272727272727\n",
    "Next point: tensor([[0.1446, 0.2220, 0.5091, 0.1907, 0.3460, 0.7154]]) \n",
    " Next Y tensor([3.2142], dtype=torch.float64)\n",
    "best_x:(0.14456123113632202, 0.22201000154018402, 0.5091198086738586, 0.19070346653461456, 0.34597134590148926, 0.7153558135032654)Best_y,3.214206471150968"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
